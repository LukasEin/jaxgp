{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import random, jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/LukasEin/jaxgp.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install jaxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import repeat, timeit\n",
    "\n",
    "from jaxgp.jaxgp.covar import full_covariance_matrix, sparse_covariance_matrix\n",
    "from jaxgp.jaxgp.kernels import RBF\n",
    "\n",
    "\n",
    "def fun(x, noise=0.0, key = random.PRNGKey(0)):\n",
    "    return (x[:,0]**2 + x[:,1] - 11)**2 / 800.0 + (x[:,0] + x[:,1]**2 -7)**2 / 800.0 + random.normal(key,(len(x),), dtype=jnp.float32)*noise\n",
    "\n",
    "def grad(x, noise=0.0, key = random.PRNGKey(0)):\n",
    "    dx1 = 4 * (x[:,0]**2 + x[:,1] - 11) * x[:,0] + 2 * (x[:,0] + x[:,1]**2 -7)\n",
    "    dx2 = 2 * (x[:,0]**2 + x[:,1] - 11) + 4 * (x[:,0] + x[:,1]**2 -7) * x[:,1]\n",
    "\n",
    "    return jnp.vstack((dx1, dx2)).T / 800.0 + random.normal(key,x.shape, dtype=jnp.float32)*noise\n",
    "\n",
    "# Constants\n",
    "BOUNDS = jnp.array([-5.0, 5.0])\n",
    "NUM_F_VALS = 1\n",
    "KERNEL = RBF()\n",
    "KERNEL_PARAMS = jnp.ones(2)*jnp.log(2)\n",
    "NOISE = 0.02\n",
    "\n",
    "def _train_data(num_d_vals):\n",
    "    # initial seed for the pseudo random key generation\n",
    "    seed = 3\n",
    "\n",
    "    # create new keys and randomly sample the above interval for training features\n",
    "    key, subkey = random.split(random.PRNGKey(seed))\n",
    "    x_func = random.uniform(subkey, (NUM_F_VALS, 2), minval=BOUNDS[0], maxval=BOUNDS[1])\n",
    "    key, subkey = random.split(key)\n",
    "    x_der = random.uniform(subkey, (num_d_vals,2), minval=BOUNDS[0], maxval=BOUNDS[1])\n",
    "\n",
    "    X_split = [x_func,x_der]\n",
    "\n",
    "    key, subkey = random.split(key)\n",
    "    y_func = fun(x_func, NOISE, subkey)\n",
    "    key, subkey = random.split(key)\n",
    "    y_der = grad(x_der, NOISE, subkey)\n",
    "\n",
    "    Y_train = jnp.hstack((y_func, y_der.reshape(-1)))\n",
    "\n",
    "    return X_split, Y_train\n",
    "\n",
    "def ref_from_data(X_split, num_ref_points):\n",
    "    key = random.PRNGKey(0)\n",
    "    key, subkey = random.split(key)\n",
    "    X_ref_rand = random.permutation(subkey, jnp.vstack(X_split))[:num_ref_points]\n",
    "\n",
    "    return X_ref_rand\n",
    "\n",
    "def full_timing(start, stop, step):\n",
    "    times = []\n",
    "\n",
    "    for i in range(start, stop, step):\n",
    "        X_train, Y_train = _train_data(i)\n",
    "\n",
    "        def test():\n",
    "            X = jit(full_covariance_matrix)(X_train, Y_train, KERNEL, KERNEL_PARAMS, NOISE)\n",
    "\n",
    "\n",
    "        times.append(repeat(test, number=10)[1:])\n",
    "    times = jnp.array(times)\n",
    "    avg_times = jnp.mean(times, axis=1)\n",
    "    jnp.save(f\"./data/full_time_{start}_{stop}_{step}\", avg_times)\n",
    "\n",
    "def sparse_timing_fixed_percent(start, stop, step, percent):\n",
    "    times = []\n",
    "\n",
    "    for i in range(start, stop, step):\n",
    "        X_train, Y_train = _train_data(i)\n",
    "        num_ref_points = int((len(X_train[0]) + len(X_train[1]))*percent) + 1\n",
    "        X_ref = ref_from_data(X_train, num_ref_points)\n",
    "\n",
    "        def test():\n",
    "            X = jit(sparse_covariance_matrix)(X_train, Y_train, X_ref, KERNEL, KERNEL_PARAMS, NOISE)\n",
    "\n",
    "\n",
    "        times.append(repeat(test, number=10)[1:])\n",
    "    times = jnp.array(times)\n",
    "    avg_times = jnp.mean(times, axis=1)\n",
    "    jnp.save(f\"./data/sparse_time_{start}_{stop}_{step}_{percent}\", avg_times)\n",
    "\n",
    "def sparse_timing_fixed_max(num_data):\n",
    "    X_train, Y_train = _train_data(num_data)\n",
    "    times = []\n",
    "\n",
    "    percentages = jnp.linspace(0,1,50)\n",
    "\n",
    "    for percent in percentages:\n",
    "        num_ref_points = int((len(X_train[0]) + len(X_train[1]))*percent) + 1\n",
    "        X_ref = ref_from_data(X_train, num_ref_points)\n",
    "\n",
    "        def test():\n",
    "            X = jit(sparse_covariance_matrix)(X_train, Y_train, X_ref, KERNEL, KERNEL_PARAMS, NOISE)\n",
    "\n",
    "        times.append(repeat(test, number=10)[1:])\n",
    "\n",
    "    times = jnp.array(times)\n",
    "    avg_times = jnp.mean(times, axis=1)\n",
    "    jnp.save(f\"./data/sparse_time_{num_data}\", avg_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_timing(10, 500, 10)\n",
    "full_timing(500, 1001, 100)\n",
    "full_timing(1200, 3000, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_timing_fixed_percent(10, 500, 10, 0.05)\n",
    "sparse_timing_fixed_percent(500, 1001, 100, 0.05)\n",
    "sparse_timing_fixed_percent(1200, 3000, 200, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_timing_fixed_max(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! zip -r data.zip data/ "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
