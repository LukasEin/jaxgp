{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import matplotlib.pyplot as plt\n",
    "import jaxgp.regression as gpr\n",
    "from jaxgp.kernels import RBF, Linear\n",
    "import time\n",
    "\n",
    "from jaxgp.tests import testfunctions, optimizertesting\n",
    "from jaxgp.utils import Logger"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from jax import vmap, jit, grad\n",
    "# sigma = 0.15\n",
    "\n",
    "# def f(x):\n",
    "#     return jnp.exp(-(x / sigma)**2) + 0.5*jnp.exp(-0.5*((x-0.5) / sigma)**2)\n",
    "\n",
    "# def df(x):\n",
    "#     return (-2*x*jnp.exp(-(x / sigma)**2) + -0.5*(x-0.5)*jnp.exp(-0.5*((x-0.5) / sigma)**2))/(sigma**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 0\n",
    "\n",
    "# noise = 0.1\n",
    "# ranges = jnp.array([0.0, 1.0])\n",
    "# num_datapoints = 1000\n",
    "# X_train = jnp.linspace(*ranges, num_datapoints).reshape(-1,1)\n",
    "# y = f(X_train)\n",
    "# dy = df(X_train)\n",
    "# Y_train = jnp.hstack((y, dy))\n",
    "\n",
    "# iters_per_optimizer = 1\n",
    "\n",
    "# function_set_sizes = [1,]\n",
    "# # derivative_set_sizes = [2,5,7,10,12,15,20, 100]\n",
    "# derivative_set_sizes = [10,]\n",
    "\n",
    "# kernel = RBF()\n",
    "# param_shape = (2,)\n",
    "# param_bounds = (1e-3, 10.0)\n",
    "\n",
    "# grid = jnp.linspace(0,1,100).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # key = random.PRNGKey(int(time.time()))\n",
    "# key = random.PRNGKey(0)\n",
    "\n",
    "# means = []\n",
    "# stds = []\n",
    "\n",
    "# for fun_vals in function_set_sizes:\n",
    "#     for der_vals in derivative_set_sizes:\n",
    "#         # logger for each pair of function vals and derivative vals\n",
    "#         logger = Logger(f\"f{fun_vals}d{der_vals}\")\n",
    "\n",
    "#         key, subkey = random.split(key)\n",
    "#         fun_perm = random.permutation(subkey, num_datapoints)[:fun_vals]\n",
    "#         key, subkey = random.split(key)\n",
    "#         d1_perm = random.permutation(subkey, num_datapoints)[:der_vals]\n",
    "\n",
    "#         X_fun = X_train[fun_perm]\n",
    "#         Y_fun = Y_train[fun_perm,0]\n",
    "#         X_d1 = X_train[d1_perm]\n",
    "#         Y_d1 = Y_train[d1_perm,1]\n",
    "\n",
    "#         X = jnp.vstack((X_fun, X_d1))\n",
    "#         Y = jnp.hstack((Y_fun, Y_d1))\n",
    "#         data_split = jnp.array([fun_vals, der_vals])\n",
    "\n",
    "#         for i in range(iters_per_optimizer):\n",
    "#             key, subkey = random.split(key)\n",
    "#             init_params = random.uniform(subkey, param_shape, minval=param_bounds[0], maxval=param_bounds[1])\n",
    "#             logger.log(f\"# iter {i+1}: init params {init_params}\")\n",
    "\n",
    "#             model = gpr.ExactGPR(kernel, init_params, noise, logger=logger)\n",
    "#             model.train(X, Y, data_split=data_split)\n",
    "#             m, s = model.eval(grid)\n",
    "#             means.append(m)\n",
    "#             stds.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(X_train, Y_train[:,0])\n",
    "# for der,mean in zip(derivative_set_sizes,means):\n",
    "#     plt.plot(grid, mean, label=f\"{der} der obs\")\n",
    "\n",
    "# plt.grid()\n",
    "# plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = [\"L-BFGS-B\", \"TNC\", \"SLSQP\"]#, \"Nelder-Mead\", \"Powell\", \"trust-constr\"]\n",
    "\n",
    "seed = 0\n",
    "num_gridpoints = jnp.array([100,100])\n",
    "noise = 0.1\n",
    "\n",
    "iters_per_optimizer = 5\n",
    "\n",
    "num_f_vals = 20\n",
    "num_d_vals = 100\n",
    "\n",
    "kernel = RBF(3)\n",
    "param_shape = (3,)\n",
    "param_bounds = (1e-3, 10.0)\n",
    "\n",
    "names = [\"franke\", \"himmelblau\", \"easom\", \"ackley\", \"sin\"]\n",
    "\n",
    "functions = [testfunctions.franke, testfunctions.himmelblau, testfunctions.easom, testfunctions.ackley, testfunctions.sin2d]\n",
    "\n",
    "ranges = [(jnp.array([0.0,1.0]), jnp.array([0.0,1.0])), \n",
    "          (jnp.array([-5.0,5.0]), jnp.array([-5.0,5.0])),\n",
    "          (jnp.array([-10.0,10.0]), jnp.array([-10.0,10.0])),\n",
    "          (jnp.array([-5.0,5.0]), jnp.array([-5.0,5.0])),\n",
    "          (jnp.array([0.0,2*jnp.pi]), jnp.array([0.0,2*jnp.pi]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizertesting.create_optimizer_data(functions, ranges, names, optimizers, num_gridpoints, noise, int(time.time()), num_f_vals, \n",
    "                                       num_d_vals, kernel, param_bounds, param_shape, iters_per_optimizer, \"./prediction_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
