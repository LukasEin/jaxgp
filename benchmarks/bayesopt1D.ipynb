{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the training data set\n",
    "\n",
    "`jax.numpy` has almost the same usage as the standard `numpy` package, with the caveat that `jax.ndarray` is an immutable type, meaning that no inplace changes can be made. For creating training data this should however not be an issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will model a simple sin function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true function is a noisy lennard jones potential\n",
    "def sin(x, noise=0.0, key = random.PRNGKey(0)):\n",
    "    return jnp.sin(x) + random.normal(key,x.shape, dtype=jnp.float32)*noise\n",
    "\n",
    "def cos(x, noise=0.0, key = random.PRNGKey(0)):\n",
    "    return jnp.cos(x) + random.normal(key,x.shape, dtype=jnp.float32)*noise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define the training data we first need to define boundaries to choose the datapoints from. Then, random points are chosen in this interval. `random.split` creates a new subkey from the previous key to get a new sudo-random sample from the uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interval bounds from which to choose the data points\n",
    "bounds = jnp.array([0.0, 2*jnp.pi])\n",
    "\n",
    "# How many function and derivative observations should be chosen\n",
    "num_f_vals = (1,)\n",
    "num_d_vals = (3,)\n",
    "\n",
    "# initial seed for the pseudo random key generation\n",
    "seed = 0\n",
    "\n",
    "# create new keys and randomly sample the above interval for training features\n",
    "key, subkey = random.split(random.PRNGKey(seed))\n",
    "x_func = random.uniform(subkey, num_f_vals, minval=bounds[0], maxval=bounds[1])\n",
    "key, subkey = random.split(key)\n",
    "x_der = random.uniform(subkey, num_d_vals, minval=bounds[0], maxval=bounds[1])\n",
    "\n",
    "# noise with which to sample the training labels\n",
    "noise = 0.1\n",
    "key, subkey = random.split(key)\n",
    "y_func = sin(x_func,noise, subkey)\n",
    "key, subkey = random.split(key)\n",
    "y_der = cos(x_der, noise, subkey)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GPR framework needs as input for training a tuple of arrays `X_split` of which contains a set of points where the function is sampled and a set of points where the gradient is sampled. Both array in `X_split` is of shape `(n_samples_i, N)`. `X_split` should be ordered as follows: the first array represents the datapoints for the function observations and the second array represents the gradient of the function. `Y_train` should just be an array of shape `(n_samples_function + n_samples_gradient,)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping needs to be done the get the arrays in the form (n_samples_i, N)\n",
    "X_split = [x_func.reshape(-1,1),x_der.reshape(-1,1)]\n",
    "\n",
    "Y_train = (y_func.reshape(-1,1), y_der.reshape(-1,1)) # jnp.hstack((y_func, y_der))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Kernel and its initial parameters\n",
    "\n",
    "The kernels can be found in `jaxgp.kernels`. Currently implemented are `RBF`, `Linear`, and `Periodic` kernels. When in doubt what kernel to use, go with an `RBF` kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxgp.kernels import RBF\n",
    "\n",
    "kernel = RBF()\n",
    "# an RBF kernel has per default 2 parameters\n",
    "init_kernel_params = jnp.array([2.0, 2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxgp.regression import ExactGPR\n",
    "\n",
    "model = ExactGPR(kernel, init_kernel_params, noise, \"L-BFGS-B\")\n",
    "model.train(X_split, jnp.vstack(Y_train).reshape(-1))\n",
    "\n",
    "predict_grid = jnp.linspace(*bounds, 200)\n",
    "means, stds = model.eval(predict_grid.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "means = means.reshape(-1)\n",
    "stds = stds.reshape(-1)\n",
    "\n",
    "plt.plot(predict_grid, means, label=\"prediction\")\n",
    "plt.fill_between(predict_grid, means-stds, means+stds, alpha=0.5)\n",
    "\n",
    "plt.plot(predict_grid, sin(predict_grid), c=\"gray\", ls=\"--\",label=\"true function\")\n",
    "\n",
    "plt.scatter(x_func, y_func, c=\"r\", label=\"function eval\")\n",
    "for i,x in enumerate(X_split[1]): \n",
    "    if i == 0:\n",
    "        plt.axvline(x, c=\"r\", lw=0.8, ls=\"--\", label=\"deriv positions\")\n",
    "    else:\n",
    "        plt.axvline(x, c=\"r\", lw=0.8, ls=\"--\")\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxgp.bayesopt import *\n",
    "\n",
    "rand = 3\n",
    "bounds = jnp.array([[0.0],[2*jnp.pi]])\n",
    "eval_func = lambda x: cos(x, noise, key)\n",
    "explore_param = 5\n",
    "grid = jnp.linspace(bounds[0], bounds[1], 200)\n",
    "\n",
    "acqui_fun = UpperConfidenceBound(grid, explore_param)\n",
    "# acqui_fun = MaximumVariance(bounds, 100)\n",
    "\n",
    "bayesopt = ExactBayesOpt(X_split, Y_train, kernel, acquisition_func=acqui_fun, eval_func=eval_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesopt(num_iters=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_split = bayesopt.X_split\n",
    "Y_train = jnp.vstack(bayesopt.Y_train).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxgp.regression import ExactGPR\n",
    "\n",
    "model = ExactGPR(kernel)\n",
    "model.train(X_split, Y_train)\n",
    "\n",
    "predict_grid = jnp.linspace(*bounds, 200)\n",
    "means, stds = model.eval(predict_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "means, stds = means.reshape(-1), stds.reshape(-1)\n",
    "\n",
    "plt.plot(predict_grid, means, label=\"prediction\")\n",
    "plt.fill_between(predict_grid.reshape(-1), means-stds, means+stds, alpha=0.5)\n",
    "\n",
    "plt.plot(predict_grid, sin(predict_grid), c=\"gray\", ls=\"--\",label=\"true function\")\n",
    "\n",
    "plt.scatter(x_func, y_func, c=\"r\", label=\"function eval\")\n",
    "for i,x in enumerate(X_split[1]): \n",
    "    if i == 0:\n",
    "        plt.axvline(x, c=\"r\", lw=0.8, ls=\"--\", label=\"deriv positions\")\n",
    "    else:\n",
    "        plt.axvline(x, c=\"r\", lw=0.8, ls=\"--\")\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
