{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "\n",
    "from jaxgp.utils import Logger\n",
    "from jaxgp.regression import SparseGPR, ExactGPR\n",
    "from jaxgp.kernels import RBF\n",
    "\n",
    "# from jaxgp.jaxgp.utils import Logger\n",
    "# from jaxgp.jaxgp.regression import SparseGPR, ExactGPR\n",
    "# from jaxgp.jaxgp.kernels import RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(x, noise=0.0, key = random.PRNGKey(0)):\n",
    "    return (x[:,0]**2 + x[:,1] - 11)**2 / 800.0 + (x[:,0] + x[:,1]**2 -7)**2 / 800.0 + random.normal(key,(len(x),), dtype=jnp.float32)*noise\n",
    "\n",
    "def grad(x, noise=0.0, key = random.PRNGKey(0)):\n",
    "    dx1 = 4 * (x[:,0]**2 + x[:,1] - 11) * x[:,0] + 2 * (x[:,0] + x[:,1]**2 -7)\n",
    "    dx2 = 2 * (x[:,0]**2 + x[:,1] - 11) + 4 * (x[:,0] + x[:,1]**2 -7) * x[:,1]\n",
    "    return jnp.vstack((dx1, dx2)).T / 800.0 + random.normal(key,x.shape, dtype=jnp.float32)*noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(num_f_vals, num_d_vals, dims, bounds, noise, fun, grad, seed=0):\n",
    "    # create new keys and randomly sample the above interval for training features\n",
    "    key, subkey = random.split(random.PRNGKey(seed))\n",
    "    x_func = random.uniform(subkey, (num_f_vals, dims), minval=bounds[0], maxval=bounds[1])\n",
    "    key, subkey = random.split(key)\n",
    "    x_der = random.uniform(subkey, (num_d_vals, dims), minval=bounds[0], maxval=bounds[1])\n",
    "\n",
    "    # noise with which to sample the training labels\n",
    "    key, subkey = random.split(key)\n",
    "    y_func = fun(x_func,noise, subkey)\n",
    "    key, subkey = random.split(key)\n",
    "    y_der = grad(x_der, noise, subkey)\n",
    "\n",
    "    return (x_func, x_der), jnp.hstack((y_func, y_der.reshape(-1)))\n",
    "\n",
    "def create_reference_points(X_train, subset_size, seed):\n",
    "    num_training_points = len(X_train[0]) + len(X_train[1])\n",
    "    num_ref_points = int((num_training_points)*subset_size + 1)\n",
    "\n",
    "    key = random.PRNGKey(seed)\n",
    "    ref_perm = random.permutation(key, num_training_points)[:num_ref_points]\n",
    "    X_ref = X_train[ref_perm]\n",
    "\n",
    "    return X_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of the function\n",
    "name = \"him\"\n",
    "# directory where to save stuff\n",
    "in_dir = \".\"\n",
    "\n",
    "# random stuff\n",
    "seed = 0\n",
    "key = random.PRNGKey(seed)\n",
    "\n",
    "# Interval bounds from which to choose the data points\n",
    "bounds = jnp.array([[-5.0, -5.0], [5.0, 5.0]])\n",
    "\n",
    "# How many function and derivative observations should be chosen\n",
    "list_f_vals = [1, 5, 20, 50]\n",
    "list_d_vals = [200, 400, 800, 1500, 2000, 3000]\n",
    "# Dimension of datapoints\n",
    "dims = 2\n",
    "\n",
    "# Noise in the data\n",
    "noise = 0.1\n",
    "\n",
    "# optimizer type\n",
    "optimizers = [\"L-BFGS-B\", \"TNC\", \"SLSQP\"]\n",
    "\n",
    "# Grid on which to evaluate the function\n",
    "eval_grid = jnp.linspace(bounds[0], bounds[1],100).T\n",
    "eval_grid = jnp.array(jnp.meshgrid(*eval_grid)).reshape(2,-1).T\n",
    "\n",
    "# Initial parameters\n",
    "param_shape = (2,)\n",
    "param_bounds = (1e-3, 10.0)\n",
    "kernel = RBF()\n",
    "\n",
    "# sparsification\n",
    "sparse = False\n",
    "subset_size = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, num_f_vals in enumerate(list_f_vals):\n",
    "    print(\"-\"*80)\n",
    "    print(f\"Number function evals: {num_f_vals}\")\n",
    "    for j, num_d_vals in enumerate(list_d_vals):        \n",
    "        print(\"-\"*80)    \n",
    "        print(f\"Number derivative evals: {num_d_vals}\")\n",
    "\n",
    "        # create new training data\n",
    "        X_train, Y_train = create_training_data(num_f_vals, num_d_vals, dims, bounds, noise, fun, grad, i*j)\n",
    "        # create new initial parameters\n",
    "        key, subkey = random.split(key)\n",
    "        init_params = random.uniform(subkey, param_shape, minval=param_bounds[0], maxval=param_bounds[1])\n",
    "        \n",
    "        if sparse:\n",
    "            X_ref = create_reference_points(X_train, subset_size, i*j)\n",
    "\n",
    "        for optimizer in optimizers:\n",
    "            print(\"-\"*80)\n",
    "            print(f\"Optimizer: {optimizer}\")\n",
    "\n",
    "            logger = Logger(optimizer)\n",
    "\n",
    "            if sparse:\n",
    "                model = SparseGPR(kernel, init_params, noise, X_ref, optimize_method=optimizer, logger=logger)\n",
    "            else:\n",
    "                model = ExactGPR(kernel, init_params, noise, optimize_method=optimizer, logger=logger)\n",
    "\n",
    "            model.train(X_train, Y_train)\n",
    "            means, stds = model.eval(eval_grid)\n",
    "\n",
    "            fname = f\"{in_dir}/{name}_d{num_d_vals}_f{num_f_vals}_{optimizer}\"\n",
    "            if sparse:\n",
    "                fname = f\"{fname}_sparse{subset_size}\"\n",
    "\n",
    "            jnp.savez(f\"{fname}_means.npz\", *means)\n",
    "            # files.download(f\"{fname}_means.npz\")\n",
    "            jnp.savez(f\"{fname}_stds.npz\", *stds)\n",
    "            # files.download(f\"{fname}_stds.npz\")\n",
    "            params = []\n",
    "            for elem in logger.iters_list:\n",
    "                params.append(elem)\n",
    "            jnp.savez(f\"{fname}_params.npz\", *params)\n",
    "            # files.download(f\"{fname}_params.npz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
