{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence behavior of the sparse GPR regressor\n",
    "\n",
    "The modelled function and its derivative were both evaluated at random datapoints and the MSE was then plotted for different numbers of function and derivative evaluations. Additionally, the procedure was done with different optimizers for the kernel parameters (`L-BFGS-B`, `SLSQP`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import testfunctions, optimizertesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = [\"L-BFGS-B\", \"SLSQP\"]#, \"TNC\"\n",
    "fun = lambda x: testfunctions.himmelblau(x)/800.0\n",
    "num_gridpoints = jnp.array([100,100])\n",
    "ran = (jnp.array([-5.0,5.0]), jnp.array([-5.0,5.0]))\n",
    "\n",
    "in_dir = \"./data_files/different_number_of_datapoints/sparse\"\n",
    "\n",
    "f_vals = [1, 5, 20, 50]\n",
    "# f_vals = [5, 20, 50]\n",
    "d_vals = [200, 400, 800, 1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,len(optimizers),figsize=(12,5),sharey=True)\n",
    "\n",
    "_, Y = optimizertesting.create_training_data_2D(0, num_gridpoints, ran, 0.0, fun)\n",
    "Y = Y[:,0]\n",
    "\n",
    "colors = [\"r\", \"b\", \"g\", \"cyan\"]\n",
    "\n",
    "for i,optimizer in enumerate(optimizers):\n",
    "    for color,num_f_vals in zip(colors,f_vals):\n",
    "        avg = []\n",
    "        mini = []\n",
    "        maxi = []\n",
    "        for num_d_vals in d_vals:\n",
    "            means = jnp.load(f\"{in_dir}/him_f{num_f_vals}d{num_d_vals}means{optimizer}_sparse0_1.npz\")\n",
    "\n",
    "            avg_mse = 0\n",
    "            min_mse = jnp.inf\n",
    "            max_mse = -jnp.inf\n",
    "            for iter, mean in enumerate(means.values()):\n",
    "                mse = jnp.mean((Y-mean)**2)\n",
    "                if mse < min_mse: min_mse = mse\n",
    "                if mse > max_mse: max_mse = mse\n",
    "                avg_mse += mse\n",
    "            avg_mse /= iter + 1\n",
    "\n",
    "            avg.append(avg_mse)\n",
    "            mini.append(min_mse)\n",
    "            maxi.append(max_mse)\n",
    "        ax[i].plot(d_vals,avg,marker=\"x\", lw=.5, ls=\"--\",label=f\"#f = {num_f_vals}\", color=color)\n",
    "        ax[i].plot(d_vals,mini, lw=.5, ls=\"--\", color=color)\n",
    "        ax[i].plot(d_vals,maxi, lw=.5, ls=\"--\", color=color)\n",
    "        ax[i].fill_between(d_vals, mini, maxi,alpha=0.5, color=color)\n",
    "    ax[i].grid()\n",
    "    ax[i].legend()\n",
    "    ax[i].set_xlabel(\"# d-vals\")\n",
    "    ax[i].set_ylabel(\"MSE averaged over inits\")\n",
    "    ax[i].set_title(optimizer)\n",
    "    ax[i].set_ylim(0,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_vals = [1, 5, 20, 50]\n",
    "# d_vals = [200, 400, 800, 1500]\n",
    "optimizer = \"L-BFGS-B\"\n",
    "# optimizer = \"SLSQP\"\n",
    "\n",
    "fig, ax = plt.subplots(len(f_vals),len(d_vals), figsize=(15,9))\n",
    "\n",
    "for i,num_f_vals in enumerate(f_vals):\n",
    "    for j,num_d_vals in enumerate(d_vals):\n",
    "        means = jnp.load(f\"{in_dir}/him_f{num_f_vals}d{num_d_vals}means{optimizer}_sparse0_1.npz\")\n",
    "        mean = means[\"arr_0\"]\n",
    "        \n",
    "        ax[i,j].set_title(f\"f{num_f_vals} d{num_d_vals}\")\n",
    "        im = ax[i,j].pcolormesh(mean.reshape(100,100))\n",
    "        fig.colorbar(im, ax=ax[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_vals = [1, 5, 20, 50]\n",
    "# d_vals = [200, 400, 800, 1500]\n",
    "optimizer = \"L-BFGS-B\"\n",
    "# optimizer = \"SLSQP\"\n",
    "\n",
    "_, Y_test = optimizertesting.create_training_data_2D(0, num_gridpoints, ran, 0.0, fun)\n",
    "Y_test = Y_test[:,0]\n",
    "\n",
    "fig, ax = plt.subplots(len(f_vals),len(d_vals), figsize=(15,9))\n",
    "\n",
    "for i,num_f_vals in enumerate(f_vals):\n",
    "    for j,num_d_vals in enumerate(d_vals):\n",
    "        means = jnp.load(f\"{in_dir}/him_f{num_f_vals}d{num_d_vals}means{optimizer}_sparse0_1.npz\")\n",
    "        mean = means[\"arr_0\"]\n",
    "        \n",
    "        im = ax[i,j].pcolormesh(jnp.abs(mean-Y_test).reshape(100,100))\n",
    "        fig.colorbar(im, ax=ax[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
