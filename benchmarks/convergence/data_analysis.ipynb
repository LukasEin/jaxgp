{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "import make_df\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(x):\n",
    "    return (x[:,0]**2 + x[:,1] - 11)**2 / 800.0 + (x[:,0] + x[:,1]**2 -7)**2 / 800.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparsification\n",
    "sparse = True\n",
    "mode = \"optim\"\n",
    "subset_size = 0.02\n",
    "sparse_dict = {0.1: \"log_sparse_0_1\", 0.02: \"log_sparse_0_02\", 0.3: \"log_sparse_0_3\", 0.005: \"log_sparse_0_005\"}\n",
    "\n",
    "if sparse:\n",
    "    # directory where to save stuff\n",
    "    in_dir = f\"./sparse/{mode}/{sparse_dict[subset_size]}\"\n",
    "\n",
    "    # How many derivative observations should be chosen\n",
    "    list_d_vals = [200, 400, 800, 1500, 2000, 3000]\n",
    "else:\n",
    "    # directory where to save stuff\n",
    "    in_dir = \"./full\"\n",
    "    # How many derivative observations should be chosen\n",
    "    list_d_vals = [5, 20, 50, 100, 200, 400, 800]\n",
    "\n",
    "\n",
    "# optimizer type\n",
    "optimizers = [\"L-BFGS-B\", \"TNC\", \"SLSQP\"]\n",
    "\n",
    "# name of the function\n",
    "name = \"him\"\n",
    "\n",
    "# How many function observations should be chosen\n",
    "list_f_vals = [1, 5, 20, 50]\n",
    "\n",
    "# Grid on which to evaluate the function\n",
    "bounds = jnp.array([[-5.0, -5.0], [5.0, 5.0]])\n",
    "eval_grid = jnp.linspace(bounds[0], bounds[1],100).T\n",
    "eval_grid = jnp.array(jnp.meshgrid(*eval_grid)).reshape(2,-1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = make_df.make_df(list_f_vals, list_d_vals, optimizers, in_dir, name, sparse, subset_size, fun, eval_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare MSE for different optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = [\"b\", \"r\", \"g\", \"cyan\"]\n",
    "\n",
    "# fig, ax = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "\n",
    "# for i, optimizer in enumerate(optimizers):\n",
    "#     opt_data = data[data[\"opt\"] == optimizer]\n",
    "#     for c,f in zip(colors, opt_data[\"f\"].unique()):\n",
    "#         temp = opt_data[opt_data[\"f\"] == f]\n",
    "#         dvals = temp[\"d\"]\n",
    "\n",
    "#         # mean_mse = temp[\"mean_mse\"]\n",
    "#         median_mse = temp[\"median_mse\"]\n",
    "#         min_mse = temp[\"min_mse\"]\n",
    "#         max_mse = temp[\"max_mse\"]\n",
    "#         # ax[i].plot(dvals, mean_mse, color=c, ls=\"--\", marker=\"x\", label=f\"#f-vals = {f}\")\n",
    "#         ax[i].plot(dvals, median_mse, color=c, ls=\"--\", marker=\"x\", label=f\"#f-vals = {f}\")\n",
    "#         ax[i].fill_between(dvals, min_mse.tolist(), max_mse.tolist(), color=c, alpha=0.2)\n",
    "#         ax[i].set_yscale(\"log\")\n",
    "#         ax[i].set_xscale(\"log\")\n",
    "\n",
    "\n",
    "#     ax[i].grid()\n",
    "#     ax[i].legend()\n",
    "#     ax[i].set_xlabel(\"#d-vals\")\n",
    "#     ax[i].set_title(optimizer)\n",
    "\n",
    "# ax[0].set_ylabel(\"MSE\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare percentage of True function in $1\\sigma$ confidence interval for different optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = [\"b\", \"r\", \"g\", \"cyan\"]\n",
    "\n",
    "# fig, ax = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "\n",
    "# for i, optimizer in enumerate(optimizers):\n",
    "#     opt_data = data[data[\"opt\"] == optimizer]\n",
    "#     for c,f in zip(colors, opt_data[\"f\"].unique()):\n",
    "#         temp = opt_data[opt_data[\"f\"] == f]\n",
    "#         dvals = temp[\"d\"]\n",
    "\n",
    "#         mean_tic = temp[\"mean_tic\"]\n",
    "#         min_tic = temp[\"min_tic\"]\n",
    "#         max_tic = temp[\"max_tic\"]\n",
    "#         ax[i].plot(dvals, mean_tic, color=c, ls=\"--\", marker=\"x\", label=f\"#f-vals = {f}\")\n",
    "#         ax[i].fill_between(dvals, min_tic.tolist(), max_tic.tolist(), color=c, alpha=0.2)\n",
    "\n",
    "\n",
    "#     ax[i].grid()\n",
    "#     ax[i].legend()\n",
    "#     ax[i].set_xlabel(\"#d-vals\")\n",
    "#     ax[i].set_title(optimizer)\n",
    "# ax[0].set_ylabel(\"% Y inside conf.-interval\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare predicted error for different optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = [\"b\", \"r\", \"g\", \"cyan\"]\n",
    "\n",
    "# fig, ax = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "\n",
    "# for i, optimizer in enumerate(optimizers):\n",
    "#     opt_data = data[data[\"opt\"] == optimizer]\n",
    "#     for c,f in zip(colors, opt_data[\"f\"].unique()):\n",
    "#         temp = opt_data[opt_data[\"f\"] == f]\n",
    "#         dvals = temp[\"d\"]\n",
    "\n",
    "#         mean_tic = temp[\"median_maxerrs\"]\n",
    "#         min_tic = temp[\"min_maxerrs\"]\n",
    "#         max_tic = temp[\"max_maxerrs\"]\n",
    "#         ax[i].plot(dvals, mean_tic, color=c, ls=\"--\", marker=\"x\", label=f\"#f-vals = {f}\")\n",
    "#         ax[i].fill_between(dvals, min_tic.tolist(), max_tic.tolist(), color=c, alpha=0.2)\n",
    "#         ax[i].set_yscale(\"log\")\n",
    "#         ax[i].set_xscale(\"log\")\n",
    "\n",
    "\n",
    "#     ax[i].grid()\n",
    "#     ax[i].legend()\n",
    "#     ax[i].set_xlabel(\"#d-vals\")\n",
    "#     ax[i].set_title(optimizer)\n",
    "# ax[0].set_ylabel(\"predicted standard error\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison between different sparsifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = [\"b\", \"r\", \"g\", \"cyan\"]\n",
    "# list_d_vals = [200, 400, 800, 1500, 2000, 3000]\n",
    "\n",
    "# fig, ax = plt.subplots(2, 2, figsize=(10, 8), sharey=True)\n",
    "\n",
    "# sparse_list = [[0.005, 0.02], [0.1, 0.3]]\n",
    "# optimizers = [\"SLSQP\"]\n",
    "\n",
    "# for i, elem in enumerate(sparse_list):\n",
    "#     for j, sparse in enumerate(elem):\n",
    "#         in_dir = f\"./sparse/{mode}/{sparse_dict[sparse]}\"\n",
    "#         data = make_df.make_df(list_f_vals, list_d_vals, optimizers, in_dir, name, True, sparse, fun, eval_grid)\n",
    "#         opt_data = data[data[\"opt\"] == optimizers[0]]\n",
    "#         for c,f in zip(colors, opt_data[\"f\"].unique()):\n",
    "#             temp = opt_data[opt_data[\"f\"] == f]\n",
    "#             dvals = temp[\"d\"]\n",
    "\n",
    "#             # mean_mse = temp[\"mean_mse\"]\n",
    "#             median_mse = temp[\"median_mse\"]\n",
    "#             min_mse = temp[\"min_mse\"]\n",
    "#             max_mse = temp[\"max_mse\"]\n",
    "#             # ax[i].plot(dvals, mean_mse, color=c, ls=\"--\", marker=\"x\", label=f\"#f-vals = {f}\")\n",
    "#             ax[i,j].plot(dvals, median_mse, color=c, ls=\"--\", marker=\"x\", label=f\"#f-vals = {f}\")\n",
    "#             ax[i,j].fill_between(dvals, min_mse.tolist(), max_mse.tolist(), color=c, alpha=0.2)\n",
    "#             ax[i,j].set_yscale(\"log\")\n",
    "#             ax[i,j].set_xscale(\"log\")\n",
    "\n",
    "\n",
    "#         ax[i,j].grid()\n",
    "#         # ax[i,j].legend()\n",
    "#         ax[i,j].set_title(sparse)\n",
    "\n",
    "# ax[1,0].set_xlabel(\"#d-vals\")\n",
    "# ax[1,1].set_xlabel(\"#d-vals\")\n",
    "# ax[0,0].set_ylabel(\"MSE\")\n",
    "# ax[1,0].set_ylabel(\"MSE\")\n",
    "# fig.suptitle(\"MSE over training set size for different sparsification\")\n",
    "# handles, labels = ax[0,0].get_legend_handles_labels()\n",
    "# fig.legend(handles, labels, loc='lower center', ncols=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparse different sparsifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"even\"\n",
    "optimizers = [\"SLSQP\"]\n",
    "\n",
    "sparse_list = [0.02, 0.1, 0.3]\n",
    "# sparse_list = [0.005, 0.02, 0.1, 0.3]\n",
    "\n",
    "list_f_vals = [1, 5, 20, 50]\n",
    "list_d_vals = [200, 400, 800, 1500, 2000, 3000]\n",
    "\n",
    "colors = [\"b\", \"r\", \"g\", \"cyan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_data_sparse():\n",
    "    medians = []\n",
    "    means = []\n",
    "    stds = []\n",
    "    mins = []\n",
    "    maxs = []\n",
    "\n",
    "    for sparse in sparse_list:\n",
    "        in_dir = f\"./sparse/{mode}/{sparse_dict[sparse]}\"\n",
    "        data = make_df.make_df(list_f_vals, list_d_vals, optimizers, in_dir, name, True, sparse, fun, eval_grid)\n",
    "        opt_data = data[data[\"opt\"] == optimizers[0]]\n",
    "\n",
    "        median_mse = []\n",
    "        mean_mse = []\n",
    "        std_mse = []\n",
    "        min_mse = []\n",
    "        max_mse = []\n",
    "\n",
    "        for f in opt_data[\"f\"].unique():\n",
    "            temp = opt_data[opt_data[\"f\"] == f]\n",
    "\n",
    "            median_mse.append(list(temp[\"median_mse\"]))\n",
    "            mean_mse.append(list(temp[\"mean_mse\"]))\n",
    "            std_mse.append(list(temp[\"std_mse\"]))\n",
    "            min_mse.append(list(temp[\"min_mse\"]))\n",
    "            max_mse.append(list(temp[\"max_mse\"]))\n",
    "\n",
    "        medians.append(median_mse)\n",
    "        means.append(mean_mse)\n",
    "        stds.append(std_mse)\n",
    "        mins.append(min_mse)\n",
    "        maxs.append(max_mse)\n",
    "\n",
    "    return jnp.array(medians), jnp.array(means), jnp.array(stds), jnp.array(mins), jnp.array(maxs)\n",
    "    # shape (sparse_types, n_f, n_d)\n",
    "\n",
    "def plotting_data_full():\n",
    "    in_dir = f\"./full/log_full\"\n",
    "    data = make_df.make_df(list_f_vals, list_d_vals, optimizers, in_dir, name, False, sparse, fun, eval_grid)\n",
    "    opt_data = data[data[\"opt\"] == optimizers[0]]\n",
    "\n",
    "    median_mse = []\n",
    "    mean_mse = []\n",
    "    std_mse = []\n",
    "    min_mse = []\n",
    "    max_mse = []\n",
    "\n",
    "    for f in opt_data[\"f\"].unique():\n",
    "        temp = opt_data[opt_data[\"f\"] == f]\n",
    "\n",
    "        median_mse.append(list(temp[\"median_mse\"]))\n",
    "        mean_mse.append(list(temp[\"mean_mse\"]))\n",
    "        std_mse.append(list(temp[\"std_mse\"]))\n",
    "        min_mse.append(list(temp[\"min_mse\"]))\n",
    "        max_mse.append(list(temp[\"max_mse\"]))\n",
    "\n",
    "    return jnp.array(median_mse), jnp.array(mean_mse), jnp.array(std_mse), jnp.array(min_mse), jnp.array(max_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_mse_sparse, mean_mse_sparse, std_mse_sparse, min_mse_sparse, max_mse_sparse = plotting_data_sparse()\n",
    "median_mse_full, mean_mse_full, std_mse_full, min_mse_full, max_mse_full = plotting_data_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, len(list_f_vals), figsize=(5*len(list_f_vals),5), sharey=True)\n",
    "\n",
    "for i, f in enumerate(list_f_vals):\n",
    "    for j,(c, s) in enumerate(zip(colors, sparse_list)):\n",
    "        # mean_mse = mean_mse_sparse[j,i]\n",
    "        median_mse = median_mse_sparse[j,i]\n",
    "        # std_mse = std_mse_sparse[j,i]\n",
    "        min_mse = min_mse_sparse[j,i]\n",
    "        max_mse = max_mse_sparse[j,i]\n",
    "\n",
    "        ax[i].plot(list_d_vals, median_mse, color=c, ls=\"--\", marker=\"x\", label=f\"sp={s}\")\n",
    "        ax[i].fill_between(list_d_vals, min_mse, max_mse, alpha=0.2, color=c)\n",
    "    \n",
    "    ax[i].plot(list_d_vals, mean_mse_full[i], color=\"magenta\", ls=\"--\", marker=\"x\", label=f\"full\")\n",
    "    ax[i].fill_between(list_d_vals, min_mse_full[i], max_mse_full[i], alpha=0.2, color=\"magenta\")\n",
    "\n",
    "    ax[i].set_yscale(\"log\")\n",
    "    ax[i].set_xscale(\"log\")\n",
    "    ax[i].legend()\n",
    "    ax[i].grid()\n",
    "    ax[i].set_title(f\"{f} function vals\")\n",
    "    ax[i].set_xlabel(\"num gradient vals\")\n",
    "\n",
    "ax[0].set_ylabel(\"MSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, len(list_d_vals), figsize=(5*len(list_d_vals),5), sharey=True)\n",
    "\n",
    "for i, d in enumerate(list_d_vals):\n",
    "    for j,(c, s) in enumerate(zip(colors, sparse_list)):\n",
    "        median_mse = median_mse_sparse[j,:,i]\n",
    "        min_mse = min_mse_sparse[j,:,i]\n",
    "        max_mse = max_mse_sparse[j,:,i]\n",
    "\n",
    "        ax[i].plot(list_f_vals, median_mse, color=c, ls=\"--\", marker=\"x\", label=f\"sp={s}\")\n",
    "        ax[i].fill_between(list_f_vals, min_mse, max_mse, alpha=0.2, color=c)\n",
    "        \n",
    "    ax[i].plot(list_f_vals, median_mse_full[:,i], color=\"magenta\", ls=\"--\", marker=\"x\", label=f\"full\")\n",
    "    ax[i].fill_between(list_f_vals, min_mse_full[:,i], max_mse_full[:,i], alpha=0.2, color=\"magenta\")\n",
    "    \n",
    "    ax[i].set_yscale(\"log\")\n",
    "    ax[i].set_xscale(\"log\")\n",
    "    ax[i].legend()\n",
    "    ax[i].grid()\n",
    "    ax[i].set_title(f\"{d} gradient vals\")\n",
    "    ax[i].set_xlabel(\"num function vals\")\n",
    "\n",
    "ax[0].set_ylabel(\"MSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
