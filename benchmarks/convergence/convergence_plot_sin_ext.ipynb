{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different extensions for 2d sin function\n",
    "\n",
    "This notebook studies the convergence behavior of the MSE over the number of function and derivative observations.\n",
    "\n",
    "Additionally the model is trained on the $[0,\\pi]\\times[0,\\pi]$ square and then tested on $[0,1.5\\pi]\\times[0,1.5\\pi]$ and $[0,2\\pi]\\times[0,2\\pi]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import testfunctions, optimizertesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = [\"L-BFGS-B\", \"TNC\", \"SLSQP\"]\n",
    "\n",
    "fun = testfunctions.sin2d\n",
    "num_gridpoints = jnp.array([100,100])\n",
    "\n",
    "in_dir = \"./data_files/different_number_of_datapoints/extended/periodic\"\n",
    "\n",
    "noise = 0.1\n",
    "seed = 0\n",
    "\n",
    "f_vals = [1, 5, 20, 50]\n",
    "d_vals = [5, 20, 50, 100, 200, 400, 800]\n",
    "\n",
    "iters_per_optimizer = 5\n",
    "\n",
    "test_rans = [(jnp.array([0.0,1.5*jnp.pi]), jnp.array([0.0,1.5*jnp.pi])),\n",
    "                (jnp.array([0.0,2*jnp.pi]), jnp.array([0.0,2*jnp.pi]))]\n",
    "names = [\"1.5\"]#, \"2.0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"r\", \"b\", \"g\", \"cyan\"]\n",
    "\n",
    "for i,(name, test_ran) in enumerate(zip(names, test_rans)):\n",
    "    fig, ax = plt.subplots(1,len(optimizers),figsize=(12,4),sharey=True)\n",
    "\n",
    "    _, Y = optimizertesting.create_training_data_2D(0, num_gridpoints, test_ran, 0.0, fun)\n",
    "    Y = Y[:,0]\n",
    "    for j,optimizer in enumerate(optimizers):\n",
    "        for color,num_f_vals in zip(colors,f_vals):\n",
    "            avg = []\n",
    "            mini = []\n",
    "            maxi = []\n",
    "            for num_d_vals in d_vals:\n",
    "                means = jnp.load(f\"{in_dir}/sin_{name}pi_f{num_f_vals}d{num_d_vals}means{optimizer}.npz\")\n",
    "\n",
    "                avg_mse = 0\n",
    "                min_mse = jnp.inf\n",
    "                max_mse = -jnp.inf\n",
    "                for iter, mean in enumerate(means.values()):\n",
    "                    mse = jnp.mean((Y-mean)**2)\n",
    "                    if mse < min_mse: min_mse = mse\n",
    "                    if mse > max_mse: max_mse = mse\n",
    "                    avg_mse += mse\n",
    "                avg_mse /= iter + 1\n",
    "\n",
    "                avg.append(avg_mse)\n",
    "                mini.append(min_mse)\n",
    "                maxi.append(max_mse)\n",
    "            ax[j].plot(d_vals,avg,marker=\"x\", lw=.5, ls=\"--\",label=f\"#f = {num_f_vals}\", color=color)\n",
    "            ax[j].plot(d_vals,mini, lw=.5, ls=\"--\", color=color)\n",
    "            ax[j].plot(d_vals,maxi, lw=.5, ls=\"--\", color=color)\n",
    "            ax[j].fill_between(d_vals, mini, maxi,alpha=0.5, color=color)\n",
    "        ax[j].grid()\n",
    "        ax[j].legend()\n",
    "        ax[j].set_xlabel(\"# d-vals\")\n",
    "        ax[j].set_ylabel(\"MSE averaged over inits\")\n",
    "        ax[j].set_title(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = \"TNC\"\n",
    "optimizer = \"L-BFGS-B\"\n",
    "# optimizer = \"SLSQP\"\n",
    "\n",
    "for name, test_ran in zip(names, test_rans):\n",
    "    fig, ax = plt.subplots(4,7, figsize=(25,12))\n",
    "    for i,num_f_vals in enumerate(f_vals):\n",
    "        for j,num_d_vals in enumerate(d_vals):\n",
    "            means = jnp.load(f\"{in_dir}/sin_{name}pi_f{num_f_vals}d{num_d_vals}means{optimizer}.npz\")\n",
    "            mean = means[\"arr_1\"]\n",
    "            \n",
    "            ax[i,j].set_title(f\"f{num_f_vals} d{num_d_vals}\")\n",
    "            im = ax[i,j].pcolormesh(mean.reshape(100,100))\n",
    "            fig.colorbar(im, ax=ax[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = \"TNC\"\n",
    "optimizer = \"L-BFGS-B\"\n",
    "# optimizer = \"SLSQP\"\n",
    "\n",
    "for name, test_ran in zip(names, test_rans):\n",
    "    fig, ax = plt.subplots(4,7, figsize=(25,12))\n",
    "\n",
    "    _, Y_test = optimizertesting.create_training_data_2D(seed, num_gridpoints, test_ran, 0.0, fun)\n",
    "    Y_test = Y_test[:,0]\n",
    "    for i,num_f_vals in enumerate(f_vals):\n",
    "        for j,num_d_vals in enumerate(d_vals):\n",
    "            means = jnp.load(f\"{in_dir}/sin_{name}pi_f{num_f_vals}d{num_d_vals}means{optimizer}.npz\")\n",
    "            mean = means[\"arr_1\"]\n",
    "            \n",
    "            ax[i,j].set_title(f\"f{num_f_vals} d{num_d_vals}\")\n",
    "            im = ax[i,j].pcolormesh(jnp.abs(mean-Y_test).reshape(100,100))\n",
    "            fig.colorbar(im, ax=ax[i,j])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
