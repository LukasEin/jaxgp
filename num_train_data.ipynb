{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from jaxgp.tests import testfunctions, optimizertesting\n",
    "\n",
    "from jaxgp.utils import Logger\n",
    "from jaxgp.kernels import RBF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial playing around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_gridpoints = jnp.array([100,100])\n",
    "# ran = (jnp.array([-5.0,5.0]), jnp.array([-5.0,5.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y = optimizertesting.create_training_data_2D(0, num_gridpoints, ran, 0.0, testfunctions.himmelblau)\n",
    "# Y = Y[:,0]\n",
    "\n",
    "# means = jnp.load(\"./prediction_files/himmelblaumeansTNC.npz\")\n",
    "# stds = jnp.load(\"./prediction_files/himmelblaustdsTNC.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut = -1\n",
    "# Y_slice = Y.reshape(100,100)\n",
    "# Y_slice = Y_slice[:,cut]\n",
    "# mean_slice = means[\"arr_3\"].reshape(100,100)\n",
    "# mean_slice = mean_slice[:,cut]\n",
    "# std_slice = stds[\"arr_3\"].reshape(100,100)\n",
    "# std_slice = std_slice[:,cut]\n",
    "\n",
    "# x = jnp.linspace(*ran[0], 100)\n",
    "\n",
    "# plt.plot(x,mean_slice)\n",
    "# plt.fill_between(x, mean_slice-std_slice, mean_slice+std_slice, alpha=0.5)\n",
    "# plt.plot(x,Y_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.pcolormesh(jnp.abs(Y-means[\"arr_3\"]).reshape(100,100))\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.pcolormesh(Y.reshape(100,100))\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.pcolormesh(means[\"arr_3\"].reshape(100,100))\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.pcolormesh(stds[\"arr_3\"].reshape(100,100))\n",
    "# plt.colorbar()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = [\"L-BFGS-B\", \"TNC\", \"SLSQP\"]\n",
    "fun = lambda x: testfunctions.himmelblau(x)/800.0\n",
    "num_gridpoints = jnp.array([100,100])\n",
    "ran = (jnp.array([-5.0,5.0]), jnp.array([-5.0,5.0]))\n",
    "\n",
    "in_dir = \"./data_files/himmelblau_different_number_of_derivatives\"\n",
    "\n",
    "noise = 0.1\n",
    "seed = 0\n",
    "\n",
    "grid1 = jnp.linspace(*ran[0],100)\n",
    "grid2 = jnp.linspace(*ran[1],100)\n",
    "grid = jnp.array(jnp.meshgrid(grid1, grid2)).reshape(2,-1).T\n",
    "\n",
    "num_f_vals = 1\n",
    "d_vals = [5, 10, 15, 20, 30, 40, 50]#, 70, 90, 100, 120, 150, 180]\n",
    "# d_vals = [200, 300, 400, 500, 1000]\n",
    "\n",
    "kernel = RBF(3)\n",
    "param_shape = (3,)\n",
    "param_bounds = (1e-3, 10.0)\n",
    "\n",
    "iters_per_optimizer = 5\n",
    "\n",
    "X_train, Y_train = optimizertesting.create_training_data_2D(seed, num_gridpoints, ran, noise, fun)\n",
    "\n",
    "for num_d_vals in d_vals:\n",
    "    for optimizer in optimizers:\n",
    "        print(f\"Optimizer {optimizer}\")\n",
    "        logger = Logger(optimizer)\n",
    "\n",
    "        means, stds = optimizertesting.create_test_data_2D(X_train=X_train, Y_train=Y_train, num_f_vals=num_f_vals, num_d_vals=num_d_vals,\n",
    "                                            logger=logger, kernel=kernel, param_bounds=param_bounds, param_shape=param_shape, noise=noise, optimizer=optimizer,iters=iters_per_optimizer, evalgrid=grid, seed=seed)\n",
    "        \n",
    "        jnp.savez(f\"{in_dir}/him_dvals{num_d_vals}means{optimizer}\", *means)\n",
    "        jnp.savez(f\"{in_dir}/him_dvals{num_d_vals}stds{optimizer}\", *stds)\n",
    "        params = []\n",
    "        losses = []\n",
    "        for elem in logger.iters_list:\n",
    "            params.append(elem[0])\n",
    "            losses.append(elem[1])\n",
    "        jnp.savez(f\"{in_dir}/him_dvals{num_d_vals}params{optimizer}\", *params)\n",
    "        jnp.savez(f\"{in_dir}/him_dvals{num_d_vals}losses{optimizer}\", *losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_d_vals in d_vals:\n",
    "    _, Y = optimizertesting.create_training_data_2D(0, num_gridpoints, ran, 0.0, fun)\n",
    "    Y = Y[:,0]\n",
    "    \n",
    "    print(\"-\"*70 + \"\\n\")\n",
    "    print(f\"Current number of derivative evaluations: {num_d_vals}\\n\")\n",
    "    \n",
    "    for optimizer in optimizers:\n",
    "        means = jnp.load(f\"{in_dir}/him_dvals{num_d_vals}means{optimizer}.npz\")\n",
    "        stds = jnp.load(f\"{in_dir}/him_dvals{num_d_vals}stds{optimizer}.npz\")\n",
    "\n",
    "        print(f\"optimizer: {optimizer}\\n\")\n",
    "\n",
    "        for iter, (mean, std) in enumerate(zip(means.values(), stds.values())):\n",
    "            conf68 = jnp.where(jnp.abs(Y-mean) <= std, 0, 1)\n",
    "            conf95 = jnp.where(jnp.abs(Y-mean) <= 2*std, 0, 1)\n",
    "\n",
    "            mse = jnp.mean((Y-mean)**2)\n",
    "\n",
    "            maxdiff = jnp.max(jnp.abs(Y-mean))\n",
    "            maxstd = jnp.max(std)\n",
    "\n",
    "            print(f\"iter {iter}: 68% = {jnp.mean(conf68):.5f}, 95% = {jnp.mean(conf95):.5f}, maxerr = {maxdiff:.5f}, mse = {mse:.5f}, maxstd = {maxstd:.5f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_vals = [5, 10, 15, 20]\n",
    "\n",
    "fig, ax = plt.subplots(1,4, figsize=(12,3))\n",
    "\n",
    "for i,num_d_vals in enumerate(d_vals):\n",
    "    means = jnp.load(f\"{in_dir}/him_dvals{num_d_vals}meansL-BFGS-B.npz\")\n",
    "    mean = means[\"arr_0\"]\n",
    "    \n",
    "    im = ax[i].pcolormesh(mean.reshape(100,100))\n",
    "    fig.colorbar(im, ax=ax[i])\n",
    "\n",
    "im = ax[-1].pcolormesh(Y.reshape(100,100))\n",
    "fig.colorbar(im, ax=ax[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
